description:
    name: 1613M_scaling
    description: train 4 different atom models in lbann.

batch:
    type: lsf
    nodes: 16 # Not used for lsf
    queue: pdebug

env:
    variables:
        OUTPUT_PATH: ./XPScale
        # /p/gpfs1/brainusr/datasets/atom/enamine1B/newEnamineFrom2020q1-2_train980mSMILES.csv
        DATASETS: /p/gpfs1/brainusr/datasets/atom/combo_enamine1613M_mpro_inhib/
        EPOCH: 100
        TIME_LIMIT: 150
        WEIGHT_DIR: "weights"
        LTFB: True
        WEIGHT_INT: 10
        PPT_LIST: "0"
        ITER_PER_LTFB: 4096
        # 1612990000
#        TRAIN_SIZE: "train_enamine_all2018q1_2020q1-2_mpro_inhib_kekulized_1613mSMILES.csv"
        TRAIN_SIZE: "test_enamine_all2018q1_2020q1-2_mpro_inhib_kekulized_2010kSMILES.csv"
        LBANN_ROOT: /g/g19/vanessen/DeepLearning/lbann.git/
        LBANN_BUILD: $(LBANN_ROOT)/build/gnu.Release.lassen.llnl.gov
        APP_ROOT: $(LBANN_ROOT)/applications/ATOM
study:
    - name: train_atom
      description: train a list of models
      run:
          cmd: |
              export SPACK_ROOT=/g/g19/vanessen/spack.git; . $SPACK_ROOT/share/spack/setup-env.sh
              spack env activate -p lbann-dev-power9le
              module use $(LBANN_BUILD)/install/etc/modulefiles
              module load lbann-0.102.0
              python3 $(APP_ROOT)/train_atom_wae.py --lr=$(5LR)  --ltfb=$(LTFB) --ltfb-batch-interval=$(4LTFBBI) --dump-weights-dir=$(WEIGHT_DIR) --dump-weights-interval=$(WEIGHT_INT)  --job-name wae$(0TRIAL) --nodes=$(1NUM_NODES) --procs-per-trainer=$(3PPT) --batch-size=$(2BATCH_SIZE) --num-epochs=$(EPOCH) --sequence-length=100 --embedding-dim=42  --num-embeddings=42 --pad-index=40 --scheduler=lsf  --delimiter=0  --no-header=True --partition=pdebug  --account=candle  --time-limit=$(TIME_LIMIT) --data-filedir=$(DATASETS) --data-filename=$(TRAIN_SIZE) --data-reader-prototext=$(APP_ROOT)/smiles_data_reader.prototext --vocab=/p/gpfs1/brainusr/datasets/atom/combo_enamine1613M_mpro_inhib/enamine_all2018q1_2020q1-2_mpro_inhib_kekulized.vocab --num_train_samples=2010000 --num_test_samples=2010000
          task_queue: train_queue

merlin:
    resources:
       task_server: celery
       workers:
         lbannworkers:
           args: -l INFO --concurrency 4 --prefetch-multiplier 1 -Ofair
           steps: [all]
           batch:
             type: local
